{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Developer Documentation Welcome to Compute Studio's developer documentation! Publish Check out our guide for publishing on compute.studio . API Check out our guide for using the compute.studio API.","title":"Home"},{"location":"#developer-documentation","text":"Welcome to Compute Studio's developer documentation!","title":"Developer Documentation"},{"location":"#publish","text":"Check out our guide for publishing on compute.studio .","title":"Publish"},{"location":"#api","text":"Check out our guide for using the compute.studio API.","title":"API"},{"location":"api/auth/","text":"Authentication API endpoints that create simulations require the user to include their API Token with their request. Here a few methods for retrieving your authentication token: compute-studio-kit $ pip install compdevkit $ csk-token --username myuser --password mypass Token: your-token-here HTTPie $ http post https://compute.studio/api-token-auth/ username = hdoupe password = mypass HTTP/1.1 200 OK Allow: POST, OPTIONS { \"token\" : \"Your token here\" } Python with the Requests library In [ 1 ]: import requests In [ 2 ]: resp = requests . post ( \"https://compute.studio/api-token-auth/\" , json = { \"username\" : \"hdoupe\" , \"password\" : \"mypass\" }) In [ 3 ]: resp . json () Out [ 3 ]: { 'token' : 'Your token here' }","title":"Authentication"},{"location":"api/auth/#authentication","text":"API endpoints that create simulations require the user to include their API Token with their request. Here a few methods for retrieving your authentication token:","title":"Authentication"},{"location":"api/auth/#compute-studio-kit","text":"$ pip install compdevkit $ csk-token --username myuser --password mypass Token: your-token-here","title":"compute-studio-kit"},{"location":"api/auth/#httpie","text":"$ http post https://compute.studio/api-token-auth/ username = hdoupe password = mypass HTTP/1.1 200 OK Allow: POST, OPTIONS { \"token\" : \"Your token here\" }","title":"HTTPie"},{"location":"api/auth/#python-with-the-requests-library","text":"In [ 1 ]: import requests In [ 2 ]: resp = requests . post ( \"https://compute.studio/api-token-auth/\" , json = { \"username\" : \"hdoupe\" , \"password\" : \"mypass\" }) In [ 3 ]: resp . json () Out [ 3 ]: { 'token' : 'Your token here' }","title":"Python with the Requests library"},{"location":"api/guide/","text":"API Guide Compute Studio offers a REST API for creating simulations, viewing existing simulations, and viewing the input parameters for a given model. This is intended for users who would like to build applications on top of the Compute Studio interface or create simulations programmatically. An API token is required for requests that modify data. Find out how to get your token here . More information about the data formats that are shown below can be found in the Compute Studio publishing documentation on inputs and outputs . This guide details the Compute Studio API endpoints and schema. A more practical Python example is also provided. /[owner]/[title]/api/v1/ Used for creating simulations. Supports POST HTTP actions. Create simulation POST hdoupe/Matchups/api/v1/ Example: { \"meta_parameters\" : { \"use_full_data\" : true }, \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } } Response: HTTP/1.1 201 Created Allow: GET, POST, HEAD, OPTIONS { \"api_url\" : \"/hdoupe/Matchups/api/v1/22\" , \"creation_date\" : \"2019-05-31T10:43:03.105760-05:00\" , \"eta\" : 0 .33, \"gui_url\" : \"/hdoupe/Matchups/22/\" , \"inputs\" : { \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } , \"errors_warnings\" : { \"API\" : { \"errors\" : {} , \"warnings\" : {} } , \"GUI\" : { \"errors\" : {} , \"warnings\" : {} } , \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } , \"custom_adjustment\" : null, \"meta_parameters\" : { \"use_full_data\" : true } } , \"model_pk\" : 22 , \"outputs\" : null, \"traceback\" : null } /[owner]/[title]/api/v1/[model_pk] Used for getting simulations. Supports GET HTTP actions. Get simulation GET /hdoupe/Matchups/api/v1/22 Response: HTTP 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"inputs\" : { \"meta_parameters\" : { \"use_full_data\" : true } , \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } , \"custom_adjustment\" : null, \"errors_warnings\" : { \"API\" : { \"errors\" : {} , \"warnings\" : {} } , \"GUI\" : { \"errors\" : {} , \"warnings\" : {} } , \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } } , \"outputs\" : { \"renderable\" : [ { \"title\" : \"Max Scherzer v. All batters\" , \"media_type\" : \"bokeh\" , \"data\" : { \"html\" : \"html here\" , \"javascript\" : \"javascript here\" } } , { \"title\" : \"Max Scherzer v. Chipper Jones\" , \"media_type\" : \"bokeh\" , \"data\" : { \"html\" : \"html here\" , \"javascript\" : \"javascript here\" } } ] , \"downloadable\" : [ { \"title\" : \"Max Scherzer v. All batters\" , \"media_type\" : \"CSV\" , \"data\" : \"csv here\" } , { \"title\" : \"Max Scherzer v. Chipper Jones\" , \"media_type\" : \"CSV\" , \"data\" : \"csv here\" } ] } , \"traceback\" : null, \"creation_date\" : \"2019-05-31T11:41:22.211492-05:00\" , \"api_url\" : \"/hdoupe/Matchups/api/v1/23\" , \"gui_url\" : \"/hdoupe/Matchups/23/\" , \"eta\" : 0 .0, \"model_pk\" : 23 } /[owner]/[title]/api/v1/inputs/ Used for viewing the inputs for a given model. Supports GET and POST HTTP actions. View inputs: GET hdoupe/Matchups/api/v1/inputs/ Response: HTTP 200 OK Allow : GET , POST , HEAD , OPTIONS Content - Type : application / json Vary : Accept { \"meta_parameters\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"title\" : \"Use Full Data\" , \"value\" : [ { \"value\" : true } ], \"validators\" : { \"choice\" : { \"choices\" : [ true , false ] } } , \"description\" : \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\" , \"number_dims\" : 0 } } , \"model_parameters\" : { \"matchup\" : { \"start_date\" : { \"type\" : \"date\" , \"section_1\" : \"Date\" , \"title\" : \"Start Date\" , \"value\" : [ { \"value\" : \"2008-01-01\" , \"use_full_data\" : true } ], \"validators\" : { \"date_range\" : { \"max\" : \"end_date\" , \"min\" : \"2008-01-01\" } } , \"description\" : \"Date to start pulling statcast information\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"number_dims\" : 0 } , \"pitcher\" : { \"type\" : \"str\" , \"section_1\" : \"Parameters\" , \"title\" : \"Pitcher Name\" , \"value\" : [ { \"value\" : \"Clayton Kershaw\" , \"use_full_data\" : true } ], \"validators\" : { \"choice\" : { \"choices\" : [ \"A. J. Achter\" , \"A. J. Burnett\" , \"A. J. Cole\" , \"A. J. Ellis\" , \"A. J. Griffin\" , \"A. J. Jimenez\" , \"A. J. Minter\" , \"A. J. Morris\" , \"A. J. Murray\" , \"A. J. Pierzynski\" , \"A. J. Pollock\" , \"A. J. Reed\" , \"A. J. Schugel\" , \"AJ Ramos\" , \"Aaron Altherr\" , \"Aaron Barrett\" , ... Update with meta parameters POST /hdoupe/Matchups/api/v1/inputs/ Example: { \"meta_parameters\" : { \"use_full_data\" : true } } Response: HTTP 200 OK Allow : GET , POST , HEAD , OPTIONS Content - Type : application / json Vary : Accept { \"meta_parameters\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"title\" : \"Use Full Data\" , \"value\" : [ { \"value\" : false } ], \"validators\" : { \"choice\" : { \"choices\" : [ true , false ] } } , \"description\" : \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\" , \"number_dims\" : 0 } } , \"model_parameters\" : { \"matchup\" : { \"start_date\" : { \"type\" : \"date\" , \"section_1\" : \"Date\" , \"title\" : \"Start Date\" , \"value\" : [ { \"value\" : \"2018-01-01\" , \"use_full_data\" : false } ], \"validators\" : { \"date_range\" : { \"max\" : \"end_date\" , \"min\" : \"2008-01-01\" } } , \"description\" : \"Date to start pulling statcast information\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"number_dims\" : 0 } , \"pitcher\" : { \"type\" : \"str\" , \"section_1\" : \"Parameters\" , \"title\" : \"Pitcher Name\" , \"value\" : [ { \"value\" : \"Jacob deGrom\" , \"use_full_data\" : false } ], \"validators\" : { \"choice\" : { \"choices\" : [ \"A. J. Achter\" , \"A. J. Burnett\" , \"A. J. Cole\" , \"A. J. Ellis\" , \"A. J. Griffin\" , \"A. J. Jimenez\" , \"A. J. Minter\" , \"A. J. Morris\" , \"A. J. Murray\" , \"A. J. Pierzynski\" , ...","title":"Guide"},{"location":"api/guide/#api-guide","text":"Compute Studio offers a REST API for creating simulations, viewing existing simulations, and viewing the input parameters for a given model. This is intended for users who would like to build applications on top of the Compute Studio interface or create simulations programmatically. An API token is required for requests that modify data. Find out how to get your token here . More information about the data formats that are shown below can be found in the Compute Studio publishing documentation on inputs and outputs . This guide details the Compute Studio API endpoints and schema. A more practical Python example is also provided.","title":"API Guide"},{"location":"api/guide/#ownertitleapiv1","text":"Used for creating simulations. Supports POST HTTP actions.","title":"/[owner]/[title]/api/v1/"},{"location":"api/guide/#create-simulation","text":"POST hdoupe/Matchups/api/v1/ Example: { \"meta_parameters\" : { \"use_full_data\" : true }, \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } } Response: HTTP/1.1 201 Created Allow: GET, POST, HEAD, OPTIONS { \"api_url\" : \"/hdoupe/Matchups/api/v1/22\" , \"creation_date\" : \"2019-05-31T10:43:03.105760-05:00\" , \"eta\" : 0 .33, \"gui_url\" : \"/hdoupe/Matchups/22/\" , \"inputs\" : { \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } , \"errors_warnings\" : { \"API\" : { \"errors\" : {} , \"warnings\" : {} } , \"GUI\" : { \"errors\" : {} , \"warnings\" : {} } , \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } , \"custom_adjustment\" : null, \"meta_parameters\" : { \"use_full_data\" : true } } , \"model_pk\" : 22 , \"outputs\" : null, \"traceback\" : null }","title":"Create simulation"},{"location":"api/guide/#ownertitleapiv1model_pk","text":"Used for getting simulations. Supports GET HTTP actions.","title":"/[owner]/[title]/api/v1/[model_pk]"},{"location":"api/guide/#get-simulation","text":"GET /hdoupe/Matchups/api/v1/22 Response: HTTP 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Vary: Accept { \"inputs\" : { \"meta_parameters\" : { \"use_full_data\" : true } , \"adjustment\" : { \"matchup\" : { \"pitcher\" : \"Max Scherzer\" } } , \"custom_adjustment\" : null, \"errors_warnings\" : { \"API\" : { \"errors\" : {} , \"warnings\" : {} } , \"GUI\" : { \"errors\" : {} , \"warnings\" : {} } , \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } } , \"outputs\" : { \"renderable\" : [ { \"title\" : \"Max Scherzer v. All batters\" , \"media_type\" : \"bokeh\" , \"data\" : { \"html\" : \"html here\" , \"javascript\" : \"javascript here\" } } , { \"title\" : \"Max Scherzer v. Chipper Jones\" , \"media_type\" : \"bokeh\" , \"data\" : { \"html\" : \"html here\" , \"javascript\" : \"javascript here\" } } ] , \"downloadable\" : [ { \"title\" : \"Max Scherzer v. All batters\" , \"media_type\" : \"CSV\" , \"data\" : \"csv here\" } , { \"title\" : \"Max Scherzer v. Chipper Jones\" , \"media_type\" : \"CSV\" , \"data\" : \"csv here\" } ] } , \"traceback\" : null, \"creation_date\" : \"2019-05-31T11:41:22.211492-05:00\" , \"api_url\" : \"/hdoupe/Matchups/api/v1/23\" , \"gui_url\" : \"/hdoupe/Matchups/23/\" , \"eta\" : 0 .0, \"model_pk\" : 23 }","title":"Get simulation"},{"location":"api/guide/#ownertitleapiv1inputs","text":"Used for viewing the inputs for a given model. Supports GET and POST HTTP actions.","title":"/[owner]/[title]/api/v1/inputs/"},{"location":"api/guide/#view-inputs","text":"GET hdoupe/Matchups/api/v1/inputs/ Response: HTTP 200 OK Allow : GET , POST , HEAD , OPTIONS Content - Type : application / json Vary : Accept { \"meta_parameters\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"title\" : \"Use Full Data\" , \"value\" : [ { \"value\" : true } ], \"validators\" : { \"choice\" : { \"choices\" : [ true , false ] } } , \"description\" : \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\" , \"number_dims\" : 0 } } , \"model_parameters\" : { \"matchup\" : { \"start_date\" : { \"type\" : \"date\" , \"section_1\" : \"Date\" , \"title\" : \"Start Date\" , \"value\" : [ { \"value\" : \"2008-01-01\" , \"use_full_data\" : true } ], \"validators\" : { \"date_range\" : { \"max\" : \"end_date\" , \"min\" : \"2008-01-01\" } } , \"description\" : \"Date to start pulling statcast information\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"number_dims\" : 0 } , \"pitcher\" : { \"type\" : \"str\" , \"section_1\" : \"Parameters\" , \"title\" : \"Pitcher Name\" , \"value\" : [ { \"value\" : \"Clayton Kershaw\" , \"use_full_data\" : true } ], \"validators\" : { \"choice\" : { \"choices\" : [ \"A. J. Achter\" , \"A. J. Burnett\" , \"A. J. Cole\" , \"A. J. Ellis\" , \"A. J. Griffin\" , \"A. J. Jimenez\" , \"A. J. Minter\" , \"A. J. Morris\" , \"A. J. Murray\" , \"A. J. Pierzynski\" , \"A. J. Pollock\" , \"A. J. Reed\" , \"A. J. Schugel\" , \"AJ Ramos\" , \"Aaron Altherr\" , \"Aaron Barrett\" , ...","title":"View inputs:"},{"location":"api/guide/#update-with-meta-parameters","text":"POST /hdoupe/Matchups/api/v1/inputs/ Example: { \"meta_parameters\" : { \"use_full_data\" : true } } Response: HTTP 200 OK Allow : GET , POST , HEAD , OPTIONS Content - Type : application / json Vary : Accept { \"meta_parameters\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"title\" : \"Use Full Data\" , \"value\" : [ { \"value\" : false } ], \"validators\" : { \"choice\" : { \"choices\" : [ true , false ] } } , \"description\" : \"Flag that determines whether Matchups uses the 10 year data set or the 2018 data set.\" , \"number_dims\" : 0 } } , \"model_parameters\" : { \"matchup\" : { \"start_date\" : { \"type\" : \"date\" , \"section_1\" : \"Date\" , \"title\" : \"Start Date\" , \"value\" : [ { \"value\" : \"2018-01-01\" , \"use_full_data\" : false } ], \"validators\" : { \"date_range\" : { \"max\" : \"end_date\" , \"min\" : \"2008-01-01\" } } , \"description\" : \"Date to start pulling statcast information\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"number_dims\" : 0 } , \"pitcher\" : { \"type\" : \"str\" , \"section_1\" : \"Parameters\" , \"title\" : \"Pitcher Name\" , \"value\" : [ { \"value\" : \"Jacob deGrom\" , \"use_full_data\" : false } ], \"validators\" : { \"choice\" : { \"choices\" : [ \"A. J. Achter\" , \"A. J. Burnett\" , \"A. J. Cole\" , \"A. J. Ellis\" , \"A. J. Griffin\" , \"A. J. Jimenez\" , \"A. J. Minter\" , \"A. J. Morris\" , \"A. J. Murray\" , \"A. J. Pierzynski\" , ...","title":"Update with meta parameters"},{"location":"api/python/","text":"Python The Compute Studio REST API can easily be wrapped with a Python class to provide a more intuitive way to use the API: How do I get my API token? api = API ( \"PSLmodels\" , \"Tax-Brain\" , api_token = \"your token\" ) res = api . create ( meta_parameters = { \"data_source\" : \"PUF\" , \"year\" : 2020 , }, adjustment = { \"policy\" : { \"II_em\" : [{ \"year\" : 2020 , \"value\" : 5000 }] } } ) # output: # {'inputs': {'meta_parameters': {'year': 2020, # 'data_source': 'PUF', # 'use_full_sample': True}, # 'adjustment': {'policy': {'II_em': [{'year': 2020, 'value': 5000}]}, # 'behavior': {}}, # 'custom_adjustment': {'policy': {'II_em': {'2020': 5000}}, 'behavior': {}}, # 'errors_warnings': {'policy': {'errors': {}, 'warnings': {}}, # 'behavior': {'errors': {}, 'warnings': {}}, # 'GUI': {'errors': {}, 'warnings': {}}, # 'API': {'errors': {}, 'warnings': {}}}}, # 'outputs': None, # 'traceback': None, # 'creation_date': '2019-06-04T17:30:23.581357-05:00', # 'api_url': '/PSLmodels/Tax-Brain/api/v1/41105/', # 'gui_url': '/PSLmodels/Tax-Brain/41105/', # 'eta': 5.0, # 'model_pk': 41105} Retrieve the result as a Pandas DataFrame: result = api . results ( res [ \"model_pk\" ]) result [ \"Total Liabilities Change by Calendar Year (Billions).csv\" ] # output: # Unnamed: 0 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 # 0 Individual Income Tax Liability Change $-168.49 $-175.45 $-183.43 $-190.69 $-198.26 $-207.17 $-32.96 $-34.10 $-35.26 $-36.46 # 1 Payroll Tax Liability Change $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 # 2 Combined Payroll and Individual Income Tax Lia... $-168.49 $-175.45 $-183.43 $-190.69 $-198.26 $-207.17 $-32.96 $-34.10 $-35.26 $-36.46 View the model's inputs: api . inputs () # output: # {'meta_parameters': {'year': {'validators': {'choice': {'choices': [2013, # 2014, # 2015, # 2016, # 2017, # 2018, # 2019, # 2020, # 2021, # 2022, # 2023, # 2024, # 2025, # 2026, # 2027, # 2028]}}, # 'description': 'Year for parameters.', # 'title': 'Start Year', # 'number_dims': 0, # 'type': 'int', # 'value': [{'value': 2019}]}, # 'data_source': {'validators': {'choice': {'choices': ['PUF', 'CPS']}}, # 'description': 'Data source can be PUF or CPS', # 'title': 'Data Source', # 'number_dims': 0, # 'type': 'str', # 'value': [{'value': 'PUF'}]}, # 'use_full_sample': {'validators': {'choice': {'choices': [True, False]}}, # 'description': 'Use entire data set or a 2% sample.', # 'title': 'Use Full Sample', # 'number_dims': 0, # 'type': 'bool', # 'value': [{'value': True}]}}, # 'model_parameters': {'policy': {'CPI_offset': {'validators': {'range': {'min': -0.005, # 'max': 0.005}}, # 'section_2': 'Offsets', # 'section_1': 'Parameter Indexing', # 'description': 'Values are zero before 2017; reforms that introduce indexing with chained CPI would have values around -0.0025 beginning in the year before the first year policy parameters will have values computed with chained CPI.', # 'title': 'Decimal offset ADDED to unchained CPI to get parameter indexing rate', # 'number_dims': 0, # 'notes': \"See April 2013 CBO report entitled 'What Would Be the Effect on the Deficit of Using the Chained CPI to Index Benefit Programs and the Tax Code?', which includes this: 'The chained CPI grows more slowly than the traditional CPI does: an average of about 0.25 percentage points more slowly per year over the past decade.' <https://www.cbo.gov/publication/44089>\", # 'type': 'float', # 'value': [{'year': 2019, 'value': -0.0025}]}, # 'FICA_ss_trt': {'validators': {'range': {'min': 0, 'max': 1}}, # 'section_2': 'Social Security FICA', # 'section_1': 'Payroll Taxes', # 'description': 'Social Security FICA rate, including both employer and employee.', # 'title': 'Social Security payroll tax rate', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 0.124}]}, # 'SS_Earnings_c': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': True, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings below this amount are subjected to Social Security (OASDI) payroll tax.', # 'title': 'Maximum taxable earnings (MTE) for Social Security', # 'number_dims': 0, # 'notes': 'This parameter is indexed by the rate of growth in average wages, not by the price inflation rate.', # 'type': 'float', # 'value': [{'year': 2019, 'value': 133048.08}]}, # 'SS_Earnings_thd': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': False, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings above this threshold are subjected to Social Security (OASDI) payroll tax, in addition to earnings below the maximum taxable earnings threshold.', # 'title': 'Additional Taxable Earnings Threshold for Social Security', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 9e+99}]}, # # ... API implementation: from io import StringIO import time import os import requests import pandas as pd class APIException ( Exception ): pass class API : host = \"https://compute.studio\" def __init__ ( self , owner , title , api_token = None ): self . owner = owner self . title = title api_token = self . get_token ( api_token ) self . auth_header = { \"Authorization\" : f \"Token { api_token } \" } self . sim_url = f \" { self . host } / { owner } / { title } /api/v1/\" self . inputs_url = f \" { self . host } / { owner } / { title } /api/v1/inputs/\" def inputs ( self , meta_parameters : dict = None ): meta_parameters = meta_parameters or {} if not meta_parameters : resp = requests . get ( self . inputs_url ) else : resp = requests . post ( self . inputs_url , json = meta_parameters , ) if resp . status_code == 200 : return resp . json () raise APIException ( resp . text ) def create ( self , adjustment : dict = None , meta_parameters : dict = None ): adjustment = adjustment or {} meta_parameters = meta_parameters or {} resp = requests . post ( self . sim_url , json = { \"adjustment\" : adjustment , \"meta_parameters\" : meta_parameters }, headers = self . auth_header ) if resp . status_code == 201 : return resp . json () raise APIException ( resp . text ) def detail ( self , model_pk ): while True : resp = requests . get ( f \" { self . sim_url }{ model_pk } /\" ) if resp . status_code == 202 : pass elif resp . status_code == 200 : return resp . json () else : raise APIException ( resp . text ) time . sleep ( 20 ) def results ( self , model_pk ): result = self . detail ( model_pk ) res = {} for output in result [ \"outputs\" ][ \"downloadable\" ]: if output [ \"media_type\" ] == \"CSV\" : res [ output [ \"title\" ]] = pd . read_csv ( StringIO ( output [ \"data\" ]) ) else : print ( f ' { output [ \"media_type\" ] } not implemented yet' ) return res def get_token ( self , api_token ): if api_token : return api_token elif os . environ . get ( \"CS_API_TOKEN\" , None ) is not None : return os . environ [ \"CS_API_TOKEN\" ] elif os . path . exists ( \"~/.cs-api-token\" ): with open ( \"~/.cs-api-token\" , \"r\" ) as f : return f . read () . strip () else : raise APIException ( \"API token not found. It can be passed as an argument to \" \"this class, as an environment variable, or read from \" \"~/.cs-api-token\" )","title":"Python"},{"location":"api/python/#python","text":"The Compute Studio REST API can easily be wrapped with a Python class to provide a more intuitive way to use the API: How do I get my API token? api = API ( \"PSLmodels\" , \"Tax-Brain\" , api_token = \"your token\" ) res = api . create ( meta_parameters = { \"data_source\" : \"PUF\" , \"year\" : 2020 , }, adjustment = { \"policy\" : { \"II_em\" : [{ \"year\" : 2020 , \"value\" : 5000 }] } } ) # output: # {'inputs': {'meta_parameters': {'year': 2020, # 'data_source': 'PUF', # 'use_full_sample': True}, # 'adjustment': {'policy': {'II_em': [{'year': 2020, 'value': 5000}]}, # 'behavior': {}}, # 'custom_adjustment': {'policy': {'II_em': {'2020': 5000}}, 'behavior': {}}, # 'errors_warnings': {'policy': {'errors': {}, 'warnings': {}}, # 'behavior': {'errors': {}, 'warnings': {}}, # 'GUI': {'errors': {}, 'warnings': {}}, # 'API': {'errors': {}, 'warnings': {}}}}, # 'outputs': None, # 'traceback': None, # 'creation_date': '2019-06-04T17:30:23.581357-05:00', # 'api_url': '/PSLmodels/Tax-Brain/api/v1/41105/', # 'gui_url': '/PSLmodels/Tax-Brain/41105/', # 'eta': 5.0, # 'model_pk': 41105} Retrieve the result as a Pandas DataFrame: result = api . results ( res [ \"model_pk\" ]) result [ \"Total Liabilities Change by Calendar Year (Billions).csv\" ] # output: # Unnamed: 0 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 # 0 Individual Income Tax Liability Change $-168.49 $-175.45 $-183.43 $-190.69 $-198.26 $-207.17 $-32.96 $-34.10 $-35.26 $-36.46 # 1 Payroll Tax Liability Change $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 # 2 Combined Payroll and Individual Income Tax Lia... $-168.49 $-175.45 $-183.43 $-190.69 $-198.26 $-207.17 $-32.96 $-34.10 $-35.26 $-36.46 View the model's inputs: api . inputs () # output: # {'meta_parameters': {'year': {'validators': {'choice': {'choices': [2013, # 2014, # 2015, # 2016, # 2017, # 2018, # 2019, # 2020, # 2021, # 2022, # 2023, # 2024, # 2025, # 2026, # 2027, # 2028]}}, # 'description': 'Year for parameters.', # 'title': 'Start Year', # 'number_dims': 0, # 'type': 'int', # 'value': [{'value': 2019}]}, # 'data_source': {'validators': {'choice': {'choices': ['PUF', 'CPS']}}, # 'description': 'Data source can be PUF or CPS', # 'title': 'Data Source', # 'number_dims': 0, # 'type': 'str', # 'value': [{'value': 'PUF'}]}, # 'use_full_sample': {'validators': {'choice': {'choices': [True, False]}}, # 'description': 'Use entire data set or a 2% sample.', # 'title': 'Use Full Sample', # 'number_dims': 0, # 'type': 'bool', # 'value': [{'value': True}]}}, # 'model_parameters': {'policy': {'CPI_offset': {'validators': {'range': {'min': -0.005, # 'max': 0.005}}, # 'section_2': 'Offsets', # 'section_1': 'Parameter Indexing', # 'description': 'Values are zero before 2017; reforms that introduce indexing with chained CPI would have values around -0.0025 beginning in the year before the first year policy parameters will have values computed with chained CPI.', # 'title': 'Decimal offset ADDED to unchained CPI to get parameter indexing rate', # 'number_dims': 0, # 'notes': \"See April 2013 CBO report entitled 'What Would Be the Effect on the Deficit of Using the Chained CPI to Index Benefit Programs and the Tax Code?', which includes this: 'The chained CPI grows more slowly than the traditional CPI does: an average of about 0.25 percentage points more slowly per year over the past decade.' <https://www.cbo.gov/publication/44089>\", # 'type': 'float', # 'value': [{'year': 2019, 'value': -0.0025}]}, # 'FICA_ss_trt': {'validators': {'range': {'min': 0, 'max': 1}}, # 'section_2': 'Social Security FICA', # 'section_1': 'Payroll Taxes', # 'description': 'Social Security FICA rate, including both employer and employee.', # 'title': 'Social Security payroll tax rate', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 0.124}]}, # 'SS_Earnings_c': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': True, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings below this amount are subjected to Social Security (OASDI) payroll tax.', # 'title': 'Maximum taxable earnings (MTE) for Social Security', # 'number_dims': 0, # 'notes': 'This parameter is indexed by the rate of growth in average wages, not by the price inflation rate.', # 'type': 'float', # 'value': [{'year': 2019, 'value': 133048.08}]}, # 'SS_Earnings_thd': {'validators': {'range': {'min': 0, 'max': 9e+99}}, # 'section_2': 'Social Security FICA', # 'checkbox': False, # 'section_1': 'Payroll Taxes', # 'description': 'Individual earnings above this threshold are subjected to Social Security (OASDI) payroll tax, in addition to earnings below the maximum taxable earnings threshold.', # 'title': 'Additional Taxable Earnings Threshold for Social Security', # 'number_dims': 0, # 'notes': '', # 'type': 'float', # 'value': [{'year': 2019, 'value': 9e+99}]}, # # ...","title":"Python"},{"location":"api/python/#api-implementation","text":"from io import StringIO import time import os import requests import pandas as pd class APIException ( Exception ): pass class API : host = \"https://compute.studio\" def __init__ ( self , owner , title , api_token = None ): self . owner = owner self . title = title api_token = self . get_token ( api_token ) self . auth_header = { \"Authorization\" : f \"Token { api_token } \" } self . sim_url = f \" { self . host } / { owner } / { title } /api/v1/\" self . inputs_url = f \" { self . host } / { owner } / { title } /api/v1/inputs/\" def inputs ( self , meta_parameters : dict = None ): meta_parameters = meta_parameters or {} if not meta_parameters : resp = requests . get ( self . inputs_url ) else : resp = requests . post ( self . inputs_url , json = meta_parameters , ) if resp . status_code == 200 : return resp . json () raise APIException ( resp . text ) def create ( self , adjustment : dict = None , meta_parameters : dict = None ): adjustment = adjustment or {} meta_parameters = meta_parameters or {} resp = requests . post ( self . sim_url , json = { \"adjustment\" : adjustment , \"meta_parameters\" : meta_parameters }, headers = self . auth_header ) if resp . status_code == 201 : return resp . json () raise APIException ( resp . text ) def detail ( self , model_pk ): while True : resp = requests . get ( f \" { self . sim_url }{ model_pk } /\" ) if resp . status_code == 202 : pass elif resp . status_code == 200 : return resp . json () else : raise APIException ( resp . text ) time . sleep ( 20 ) def results ( self , model_pk ): result = self . detail ( model_pk ) res = {} for output in result [ \"outputs\" ][ \"downloadable\" ]: if output [ \"media_type\" ] == \"CSV\" : res [ output [ \"title\" ]] = pd . read_csv ( StringIO ( output [ \"data\" ]) ) else : print ( f ' { output [ \"media_type\" ] } not implemented yet' ) return res def get_token ( self , api_token ): if api_token : return api_token elif os . environ . get ( \"CS_API_TOKEN\" , None ) is not None : return os . environ [ \"CS_API_TOKEN\" ] elif os . path . exists ( \"~/.cs-api-token\" ): with open ( \"~/.cs-api-token\" , \"r\" ) as f : return f . read () . strip () else : raise APIException ( \"API token not found. It can be passed as an argument to \" \"this class, as an environment variable, or read from \" \"~/.cs-api-token\" )","title":"API implementation:"},{"location":"publish/environment/","text":"Model Environment Compute Studio runs each project in its own Docker container. Miniconda3 is used as the base image, making it easy to install any package available through the Conda package manager . An install.sh script is created for you by the csk-init command in your cs-config directory. Compute Studio will use this script to install your package. The installation instructions for the matchups project are simply a bash script: # located at: https://github.com/hdoupe/Matchups/blob/master/cs-config/install.sh conda install -c conda-forge pandas pyarrow bokeh \"paramtools>=0.5.3\" fastparquet python-snappy pip pip install git+https://github.com/hdoupe/Matchups.git@master","title":"Environment"},{"location":"publish/environment/#model-environment","text":"Compute Studio runs each project in its own Docker container. Miniconda3 is used as the base image, making it easy to install any package available through the Conda package manager . An install.sh script is created for you by the csk-init command in your cs-config directory. Compute Studio will use this script to install your package. The installation instructions for the matchups project are simply a bash script: # located at: https://github.com/hdoupe/Matchups/blob/master/cs-config/install.sh conda install -c conda-forge pandas pyarrow bokeh \"paramtools>=0.5.3\" fastparquet python-snappy pip pip install git+https://github.com/hdoupe/Matchups.git@master","title":"Model Environment"},{"location":"publish/functions/","text":"Python functions The modeling project must provide a Python function for each of the following tasks: Get Version : Get the model's version. Model Parameters : Get the default Model Parameters and their meta data. Parse user adjustments : Do model-specific formatting and validation on user adjustments. Run simulation : Submit the user adjustments (or none) to the model to run the simulation. Once you've skimmed the criteria below, you can develop your functions against the cs-kit automated testing suite . Get Version Returns the version of the model as a string. Python Example: def get_version (): return \"1.0.0\" Model Parameters Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def get_inputs ( meta_params_dict ): meta_params = matchups . MetaParams () meta_params . adjust ( meta_params_dict ) params = matchups . MatchupsParams () params . set_state ( use_full_data = True ) return { \"meta_parameters\" : meta_params . dump (), \"model_parameters\" : params . dump () } Here's what you get after filling in this function: Validate user adjustments Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). Compute Studio will provide parsed user adjustments of the form: meta_param_dict = { \"use_full_data\" : True } adjustment = { \"matchup\" : { \"start_date\" : [ { \"value\" : \"2012-08-01\" } ], \"end_date\" : [ { \"value\" : \"2012-09-01\" } ], \"pitcher\" : [ { \"value\" : \"Not a Real Pitcher\" } ] } } errors_warnings = { \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } The function should return: Warnings/Errors: { \"errors_warnings\" : { \"matchup\" : { \"errors\" : { \"pitcher\" : [ 'Pitcher \"Not a Real Pitcher\" not allowed' ] }, \"warnings\" : {} } } } Python : import matchups def validate_inputs ( meta_param_dict , adjustment , errors_warnings ): # matchups doesn't look at meta_param_dict for validating inputs. params = matchups . MatchupsParams () params . adjust ( adjustment [ \"matchup\" ], raise_errors = False ) errors_warnings [ \"matchup\" ][ \"errors\" ] . update ( params . errors ) return { \"errors_warnings\" : errors_warnings } Here's what you get after filling in this function: Run simulation Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page Compute Studio submits the model's meta parameters and the parsed and formatted user adjustments: meta_param_dict = { \"use_full_data\": True } adjustment = { \"matchup\": { \"pitcher\": \"Max Scherzer\" }, } Python Example : import matchups def get_matchup ( meta_param_dict , adjustment ): result = matchups . get_matchup ( meta_param_dict , adjustment ) return result Here's what you get after filling in this function:","title":"Functions"},{"location":"publish/functions/#python-functions","text":"The modeling project must provide a Python function for each of the following tasks: Get Version : Get the model's version. Model Parameters : Get the default Model Parameters and their meta data. Parse user adjustments : Do model-specific formatting and validation on user adjustments. Run simulation : Submit the user adjustments (or none) to the model to run the simulation. Once you've skimmed the criteria below, you can develop your functions against the cs-kit automated testing suite .","title":"Python functions"},{"location":"publish/functions/#get-version","text":"Returns the version of the model as a string. Python Example: def get_version (): return \"1.0.0\"","title":"Get Version"},{"location":"publish/functions/#model-parameters","text":"Accepts Meta Parameters, if they are being utilized. Returns data in the form specified in the inputs page . Python Example : import matchups def get_inputs ( meta_params_dict ): meta_params = matchups . MetaParams () meta_params . adjust ( meta_params_dict ) params = matchups . MatchupsParams () params . set_state ( use_full_data = True ) return { \"meta_parameters\" : meta_params . dump (), \"model_parameters\" : params . dump () } Here's what you get after filling in this function:","title":"Model Parameters"},{"location":"publish/functions/#validate-user-adjustments","text":"Accepts parsed user adjustments, separated by each major section. Returns warnings/errors (if any). Compute Studio will provide parsed user adjustments of the form: meta_param_dict = { \"use_full_data\" : True } adjustment = { \"matchup\" : { \"start_date\" : [ { \"value\" : \"2012-08-01\" } ], \"end_date\" : [ { \"value\" : \"2012-09-01\" } ], \"pitcher\" : [ { \"value\" : \"Not a Real Pitcher\" } ] } } errors_warnings = { \"matchup\" : { \"errors\" : {} , \"warnings\" : {} } } The function should return: Warnings/Errors: { \"errors_warnings\" : { \"matchup\" : { \"errors\" : { \"pitcher\" : [ 'Pitcher \"Not a Real Pitcher\" not allowed' ] }, \"warnings\" : {} } } } Python : import matchups def validate_inputs ( meta_param_dict , adjustment , errors_warnings ): # matchups doesn't look at meta_param_dict for validating inputs. params = matchups . MatchupsParams () params . adjust ( adjustment [ \"matchup\" ], raise_errors = False ) errors_warnings [ \"matchup\" ][ \"errors\" ] . update ( params . errors ) return { \"errors_warnings\" : errors_warnings } Here's what you get after filling in this function:","title":"Validate user adjustments"},{"location":"publish/functions/#run-simulation","text":"Accepts Meta Parameters values and model parameters. Returns outputs as specified in the outputs page Compute Studio submits the model's meta parameters and the parsed and formatted user adjustments: meta_param_dict = { \"use_full_data\": True } adjustment = { \"matchup\": { \"pitcher\": \"Max Scherzer\" }, } Python Example : import matchups def get_matchup ( meta_param_dict , adjustment ): result = matchups . get_matchup ( meta_param_dict , adjustment ) return result Here's what you get after filling in this function:","title":"Run simulation"},{"location":"publish/guide/","text":"Publishing on Compute Studio This guide describes how to publish a model on Compute Studio. The Compute Studio framework depends on model interfaces meeting several Compute Studio criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your Compute Studio app. If you have any questions as you proceed through this guide, send Hank an email at hank@compute.studio . Data formats Compute Studio relies on two data formats, one for the inputs and one for the outputs . These are JSON schemas that your model will need to adopt for Compute Studio to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs. Functions Compute Studio interacts with your model using 4 Python functions : one for getting the model's version, one for getting the default inputs, one for validating user inputs, and one for running the model. Publish Now it's time to publish your model. The first step is to install Compute Studio Kit via pip install cs-kit . Next, create a directory named cs-config in your model's source code repository with the command csk-init . This creates a light-weight python package that includes an installation script, a functions.py file with stubs for each of the four Python functions, and a py.test ready test suite located at cs-config/cs_config/tests/test_functions.py . Once you've filled in your functions, you can test whether they are compliant with the C/S criteria by running py.test cs-config/ . Once your functions are passing the cs-kit tests, fill out the publish form that asks you to provide a title and overview for your new Compute Studio app and a link to your model's source code repository. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to Compute Studio once it has met all of the critera. You will have the opportunity to test it out after it has been deployed.","title":"Guide"},{"location":"publish/guide/#publishing-on-compute-studio","text":"This guide describes how to publish a model on Compute Studio. The Compute Studio framework depends on model interfaces meeting several Compute Studio criteria, and we walk you through how to meet those criteria, either by modifying your model's interface or building a new wrapper interface around your model. The great part is that you don't have to deal with any web technology to build your Compute Studio app. If you have any questions as you proceed through this guide, send Hank an email at hank@compute.studio .","title":"Publishing on Compute Studio"},{"location":"publish/guide/#data-formats","text":"Compute Studio relies on two data formats, one for the inputs and one for the outputs . These are JSON schemas that your model will need to adopt for Compute Studio to be able to generate input forms representing your model's default specification, validate user adjustments, and display model outputs.","title":"Data formats"},{"location":"publish/guide/#functions","text":"Compute Studio interacts with your model using 4 Python functions : one for getting the model's version, one for getting the default inputs, one for validating user inputs, and one for running the model.","title":"Functions"},{"location":"publish/guide/#publish","text":"Now it's time to publish your model. The first step is to install Compute Studio Kit via pip install cs-kit . Next, create a directory named cs-config in your model's source code repository with the command csk-init . This creates a light-weight python package that includes an installation script, a functions.py file with stubs for each of the four Python functions, and a py.test ready test suite located at cs-config/cs_config/tests/test_functions.py . Once you've filled in your functions, you can test whether they are compliant with the C/S criteria by running py.test cs-config/ . Once your functions are passing the cs-kit tests, fill out the publish form that asks you to provide a title and overview for your new Compute Studio app and a link to your model's source code repository. If you would like to see a publishing template that has already been completed, you can view the Matchups template here . Once you've submitted the publishing form, Hank will review it and get back to you within 24 hours to inform you whether the model is ready to be published or if there are criteria that have not been satisfied. Your model will be deployed to Compute Studio once it has met all of the critera. You will have the opportunity to test it out after it has been deployed.","title":"Publish"},{"location":"publish/inputs/","text":"Inputs Compute Studio uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. Compute Studio requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it. Meta Parameters For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"start_year\" : { \"title\" : \"Start Year\" , \"description\" : \"Year for parameters.\" , \"type\" : \"int\" , \"value\" : 2019 , \"validators\" : { \"range\" : { \"min\" : 2019 , \"max\" : 2027 }} }, \"data_source\" : { \"title\" : \"Data Source\" , \"description\" : \"Data source can be PUF or CPS\" , \"type\" : \"str\" , \"value\" : \"PUF\" , \"validators\" : { \"choice\" : { \"choices\" : [ \"PUF\" , \"CPS\" ]}} }, \"use_full_sample\" : { \"title\" : \"Use Full Sample\" , \"description\" : \"Use entire data set or a 2% sample.\" , \"type\" : \"str\" , \"value\" : true , } } Compute Studio uses this information to build a set of controls that dictate which values of the default model parameters are shown: Default Parameters The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from hdoupe/Matchups : { \"schema\" : { \"labels\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"validators\" : {}} }, \"additional_parameters\" : { \"section_1\" : { \"type\" : \"str\" , \"number_dims\" : 0 }, \"section_2\" : { \"type\" : \"str\" , \"number_dims\" : 0 } } }, \"start_date\" : { \"title\" : \"Start Date\" , \"description\" : \"Date to start pulling statcast information\" , \"section_1\" : \"Date\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"type\" : \"date\" , \"value\" : [ { \"use_full_data\" : true , \"value\" : \"2008-01-01\" }, { \"use_full_data\" : false , \"value\" : \"2018-01-01\" } ], \"validators\" : { \"date_range\" : { \"min\" : \"2008-01-01\" , \"max\" : \"end_date\" }} }, \"pitcher\" : { \"title\" : \"Pitcher Name\" , \"description\" : \"Name of pitcher to pull data on\" , \"section_1\" : \"Parameters\" , \"section_2\" : \"Pitcher\" , \"type\" : \"str\" , \"value\" : \"Clayton Kershaw\" , \"validators\" : { \"choice\" : { \"choices\" : [ \"Clayton Kershaw\" , \"Jacob deGrom\" , \"Justin Verlander\" ] } } } } Compute Studio builds the model parameter GUI directly from this data:","title":"Inputs"},{"location":"publish/inputs/#inputs","text":"Compute Studio uses the ParamTools inputs format for building its GUI. ParamTools also offers functionality for updating parameter values and validating the new values. Check out the ParamTools documentation for more information on how to create your configuration files. Compute Studio requires two typs of inputs: meta parameters and model parameters. First, what are meta parameters ? Meta parameters control the default parameters. If the value of a parameter depends on the current year, then the user will need to set the current year via a meta parameter before they can view the parameter's default value and update it.","title":"Inputs"},{"location":"publish/inputs/#meta-parameters","text":"For example, the meta parameters for PSLmodels/Tax-Brain are defined like this: { \"start_year\" : { \"title\" : \"Start Year\" , \"description\" : \"Year for parameters.\" , \"type\" : \"int\" , \"value\" : 2019 , \"validators\" : { \"range\" : { \"min\" : 2019 , \"max\" : 2027 }} }, \"data_source\" : { \"title\" : \"Data Source\" , \"description\" : \"Data source can be PUF or CPS\" , \"type\" : \"str\" , \"value\" : \"PUF\" , \"validators\" : { \"choice\" : { \"choices\" : [ \"PUF\" , \"CPS\" ]}} }, \"use_full_sample\" : { \"title\" : \"Use Full Sample\" , \"description\" : \"Use entire data set or a 2% sample.\" , \"type\" : \"str\" , \"value\" : true , } } Compute Studio uses this information to build a set of controls that dictate which values of the default model parameters are shown:","title":"Meta Parameters"},{"location":"publish/inputs/#default-parameters","text":"The GUI is built directly from the default parameters. Here's an example using a subset of the inputs from hdoupe/Matchups : { \"schema\" : { \"labels\" : { \"use_full_data\" : { \"type\" : \"bool\" , \"validators\" : {}} }, \"additional_parameters\" : { \"section_1\" : { \"type\" : \"str\" , \"number_dims\" : 0 }, \"section_2\" : { \"type\" : \"str\" , \"number_dims\" : 0 } } }, \"start_date\" : { \"title\" : \"Start Date\" , \"description\" : \"Date to start pulling statcast information\" , \"section_1\" : \"Date\" , \"section_2\" : \"\" , \"notes\" : \"If using the 2018 dataset, only use dates in 2018.\" , \"type\" : \"date\" , \"value\" : [ { \"use_full_data\" : true , \"value\" : \"2008-01-01\" }, { \"use_full_data\" : false , \"value\" : \"2018-01-01\" } ], \"validators\" : { \"date_range\" : { \"min\" : \"2008-01-01\" , \"max\" : \"end_date\" }} }, \"pitcher\" : { \"title\" : \"Pitcher Name\" , \"description\" : \"Name of pitcher to pull data on\" , \"section_1\" : \"Parameters\" , \"section_2\" : \"Pitcher\" , \"type\" : \"str\" , \"value\" : \"Clayton Kershaw\" , \"validators\" : { \"choice\" : { \"choices\" : [ \"Clayton Kershaw\" , \"Jacob deGrom\" , \"Justin Verlander\" ] } } } } Compute Studio builds the model parameter GUI directly from this data:","title":"Default Parameters"},{"location":"publish/outputs/","text":"Outputs Projects should return outputs that are in the following format: { \"renderable\" : [ { \"media_type\" : \"PNG\" , \"title\" : \"My PNG\" , \"data\" : \"picture bytes here...\" } ], \"downloadable\" : [ { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output ( df , title , renderable , downloadable ): js , div = make_my_plot ( df , title ) renderable . append ( { \"media_type\" : \"bokeh\" , \"title\" : title , \"data\" : { \"javascript\" : js , \"html\" : div } } ) downloadable . append ( { \"media_type\" : \"CSV\" , \"title\" : title , \"data\" : df . to_csv () } ) downloadable = [] renderable = [] append_output ( my_df , \"My results\" , renderable , downloadable ) append_output ( my_other_df , \"My other results\" , renderable , downloadable ) A full example can be found in the Matchups package . Examples bokeh JSON format: { \"media_type\" : \"bokeh\" , \"title\" : \"My Bokeh Plot\" , \"data\" : { \"root_id\" : \"abc\" , \"target_id\" : \"123\" , \"doc\" : \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import json_item # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 6 , 7 , 2 , 4 , 5 ] # create a new plot with a title and axis labels p = figure ( title = \"simple line example\" , x_axis_label = 'x' , y_axis_label = 'y' ) # add a line renderer with legend and line thickness p . line ( x , y , legend = \"Temp.\" , line_width = 2 ) # get the results data = json_item ( p ) output = { \"media_type\" : \"bokeh\" , \"title\" : \"simple line example\" , \"data\" : data } table JSON format: { \"media_type\" : \"table\" , \"title\" : \"My Table\" , \"data\" : \"<table>...</table>\" } Python example: import pandas as pd df = pd . DataFrame ({ \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 , 6 ]}) table = df . to_html () output = { \"media_type\" : \"table\" , \"title\" : \"My Table\" , \"data\" : table } CSV JSON format: { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : \"comma,sep,values\\n\" } Python example: import pandas as pd df = pd . DataFrame ({ \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 , 6 ]}) csv = df . to_csv () output = { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : csv } PNG/JPEG JSON format: { \"media_type\" : \"PNG\" , \"title\" : \"My PNG\" , \"data\" : \"png bytes\" } Python example: import io import matplotlib.pyplot as plt import numpy as np # see: https://matplotlib.org/tutorials/introductory/usage.html#matplotlib-pyplot-and-pylab-how-are-they-related # prepare some data x = np . linspace ( 0 , 2 , 100 ) # Plot three lines plt . plot ( x , x , label = 'linear' ) plt . plot ( x , x ** 2 , label = 'quadratic' ) plt . plot ( x , x ** 3 , label = 'cubic' ) plt . title ( \"Simple Plot\" ) plt . legend () # Matplotlib needs a file-like object to write the picture data. # For speed and efficiency, io.BytesIO is used as an in-memory file. in_memory_file = io . BytesIO () plt . savefig ( in_memory_file , format = \"png\" ) # Just need to rewind back to the beginning of the file. in_memory_file . seek ( 0 ) output = { \"media_type\" : \"PNG\" , \"title\" : \"My PNG Plot\" , \"data\" : in_memory_file . read () }","title":"Outputs"},{"location":"publish/outputs/#outputs","text":"Projects should return outputs that are in the following format: { \"renderable\" : [ { \"media_type\" : \"PNG\" , \"title\" : \"My PNG\" , \"data\" : \"picture bytes here...\" } ], \"downloadable\" : [ { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : \"comma,sep,values\\n\" } ] } There are two categories of outputs: \"renderable\" and \"downloadable.\" Renderable outputs will be displayed on the outputs page while downloadable outputs are saved by the user as a zipfile. These categories are represented as the two top-level members in the JSON structure above. They point to a List of Output Objects . Each Output Object has three members: media_type , title , and data . Supported media types are: bokeh table CSV PNG JPEG MP3 MP4 Here's an example for how to create a full result in Python: def append_output ( df , title , renderable , downloadable ): js , div = make_my_plot ( df , title ) renderable . append ( { \"media_type\" : \"bokeh\" , \"title\" : title , \"data\" : { \"javascript\" : js , \"html\" : div } } ) downloadable . append ( { \"media_type\" : \"CSV\" , \"title\" : title , \"data\" : df . to_csv () } ) downloadable = [] renderable = [] append_output ( my_df , \"My results\" , renderable , downloadable ) append_output ( my_other_df , \"My other results\" , renderable , downloadable ) A full example can be found in the Matchups package .","title":"Outputs"},{"location":"publish/outputs/#examples","text":"","title":"Examples"},{"location":"publish/outputs/#bokeh","text":"JSON format: { \"media_type\" : \"bokeh\" , \"title\" : \"My Bokeh Plot\" , \"data\" : { \"root_id\" : \"abc\" , \"target_id\" : \"123\" , \"doc\" : \"<script>...</script>\" } } Python example: from bokeh.plotting import figure from bokeh.embed import json_item # see: https://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#getting-started # prepare some data x = [ 1 , 2 , 3 , 4 , 5 ] y = [ 6 , 7 , 2 , 4 , 5 ] # create a new plot with a title and axis labels p = figure ( title = \"simple line example\" , x_axis_label = 'x' , y_axis_label = 'y' ) # add a line renderer with legend and line thickness p . line ( x , y , legend = \"Temp.\" , line_width = 2 ) # get the results data = json_item ( p ) output = { \"media_type\" : \"bokeh\" , \"title\" : \"simple line example\" , \"data\" : data }","title":"bokeh"},{"location":"publish/outputs/#table","text":"JSON format: { \"media_type\" : \"table\" , \"title\" : \"My Table\" , \"data\" : \"<table>...</table>\" } Python example: import pandas as pd df = pd . DataFrame ({ \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 , 6 ]}) table = df . to_html () output = { \"media_type\" : \"table\" , \"title\" : \"My Table\" , \"data\" : table }","title":"table"},{"location":"publish/outputs/#csv","text":"JSON format: { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : \"comma,sep,values\\n\" } Python example: import pandas as pd df = pd . DataFrame ({ \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 , 6 ]}) csv = df . to_csv () output = { \"media_type\" : \"CSV\" , \"title\" : \"My CSV\" , \"data\" : csv }","title":"CSV"},{"location":"publish/outputs/#pngjpeg","text":"JSON format: { \"media_type\" : \"PNG\" , \"title\" : \"My PNG\" , \"data\" : \"png bytes\" } Python example: import io import matplotlib.pyplot as plt import numpy as np # see: https://matplotlib.org/tutorials/introductory/usage.html#matplotlib-pyplot-and-pylab-how-are-they-related # prepare some data x = np . linspace ( 0 , 2 , 100 ) # Plot three lines plt . plot ( x , x , label = 'linear' ) plt . plot ( x , x ** 2 , label = 'quadratic' ) plt . plot ( x , x ** 3 , label = 'cubic' ) plt . title ( \"Simple Plot\" ) plt . legend () # Matplotlib needs a file-like object to write the picture data. # For speed and efficiency, io.BytesIO is used as an in-memory file. in_memory_file = io . BytesIO () plt . savefig ( in_memory_file , format = \"png\" ) # Just need to rewind back to the beginning of the file. in_memory_file . seek ( 0 ) output = { \"media_type\" : \"PNG\" , \"title\" : \"My PNG Plot\" , \"data\" : in_memory_file . read () }","title":"PNG/JPEG"}]}